# Bibliographie 

https://papers.nips.cc/paper/5477-neural-word-embedding-as-implicit-matrix-factorization.pdf  

https://arxiv.org/pdf/1301.3781.pdf

# Blog
http://mccormickml.com/2016/04/19/word2vec-tutorial-the-skip-gram-model/

# Code 

https://pytorch.org/get-started/locally/  

https://rguigoures.github.io/word2vec_pytorch/

# Negative sampling

https://medium.com/towardsdatascience/word2vec-negative-sampling-made-easy-7a1a647e07a4 

https://aegis4048.github.io/optimize_computational_efficiency_of_skip-gram_with_negative_sampling#neg_drawn

# Softmax vs sigmoid
https://dejanbatanjac.github.io/2019/07/04/softmax-vs-sigmoid.html
