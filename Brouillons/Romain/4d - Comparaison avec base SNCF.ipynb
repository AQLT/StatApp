{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import gensim\n",
    "from gensim.models import word2vec\n",
    "import string\n",
    "import re\n",
    "random.seed(1)\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('C:/Users/torna/Documents/StatApp/StatApp')\n",
    "#os.chdir('C:/Users/Kim Antunez/Documents/Projets_autres')\n",
    "#os.chdir('/Users/alainquartierlatente/Desktop/Ensae/StatApp')\n",
    "#os.chdir('/home/aqlt/Documents/Ensae/StatApp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/sentimental_analysis/df_deft_sentiment.csv\",sep='|',header=0,engine='python',encoding='UTF-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['tag','tweet']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On traite la mise en forme comme dans notre corpus\n",
    "def mise_en_forme_phrase (phrase):\n",
    "    phrase = phrase.lower()\n",
    "    # On enlève la ponctuation + certaines apostrophes\n",
    "    phrase = phrase.translate(str.maketrans('', '', string.punctuation + \"'’«»—\"))\n",
    "    # On enlève les passages à la ligne\n",
    "    phrase = re.sub('\\\\n', ' ', phrase)\n",
    "    # On enlève les tabulations\n",
    "    phrase = re.sub('\\\\t', ' ', phrase)\n",
    "    # On enlève les espaces multiples et les espaces à la fin des phrases\n",
    "    phrase = re.sub(' +', ' ', phrase)\n",
    "    phrase = re.sub(' +$', '', phrase)\n",
    "    phrase = re.sub('^ +', '', phrase)\n",
    "    # phrase.isalpha() # inutile\n",
    "    return(phrase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tag        1\n",
       "tweet    NaN\n",
       "Name: 2664, dtype: object"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#(df[\"tweet\"] == \"\").value_counts()\n",
    "df.iloc[2664]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.loc[(pd.isnull(df[\"tweet\"]))==False,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1    13114\n",
       " 0    12608\n",
       " 1     7331\n",
       " 2     2417\n",
       "Name: tag, dtype: int64"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tag'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[-1,\n",
       "  'pff c est grave ce qui se passe à bruxelles on m a aussi volé les plans de mises à 4 voies des lignes rer de nivelles et ottignies'],\n",
       " [1,\n",
       "  't heure mazri il était en mode daesh dans le métro les ptits babtous ils avaient raison de pas s approcher à côté de lui']]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = []\n",
    "for ligne in df.itertuples():\n",
    "    if ligne.tag != 0:\n",
    "        corpus.append([ligne.tag,mise_en_forme_phrase(ligne.tweet)])\n",
    "corpus[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22862"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_modif = [[1 if score >= 1 else -1,tweet] for score, tweet in corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_pos = [[score,tweet] for score,tweet in corpus_modif if score == 1]\n",
    "val_neg = [[score,tweet] for score,tweet in corpus_modif if score == -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13114"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(val_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from random import sample\n",
    "random.seed(1)\n",
    "corpus_train_pos = sample(val_pos,round(0.7*len(val_pos)))\n",
    "corpus_test_pos = sample(val_pos,round(0.3*len(val_pos)))\n",
    "corpus_train_neg = sample(val_neg,round(0.7*len(val_neg)))\n",
    "corpus_test_neg = sample(val_neg,round(0.3*len(val_neg)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_train = corpus_train_pos + corpus_train_neg\n",
    "corpus_test = corpus_test_pos + corpus_test_neg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calcul modèles sur Données SNCF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcul_sentence_embedding(phrase):\n",
    "    if len(phrase)>0:\n",
    "        sum1 = sum(matrice[mot] for mot in phrase if mot in model1.wv.index2word)\n",
    "        #sum1 = sum(matrice_norm[mot] for mot in phrase if mot in model1.wv.index2word)\n",
    "        sum2 = sum(matrice[\"lowfrequencyword\"] for mot in phrase if mot not in model1.wv.index2word)\n",
    "        #sum2 = sum(matrice_norm[\"lowfrequencyword\"] for mot in phrase if mot not in model1.wv.index2word)\n",
    "        return (sum1+sum2)/len(phrase)\n",
    "    else:\n",
    "        return matrice[\"lowfrequencyword\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "nom_dossier = 'ens'\n",
    "# dim = 50\n",
    "dim = 100\n",
    "# dim = 300\n",
    "epoch = 100\n",
    "window = 4\n",
    "learning_rate = 0.02\n",
    "    \n",
    "chemin1 = \"data/{}/gensim/dim{}_ep{}_w{}_lr{}_seed1\".format(nom_dossier, dim, epoch, window, str(learning_rate)[2:]) \n",
    "model1 = gensim.models.keyedvectors.KeyedVectors.load(chemin1 + \"/word2vec.model\")\n",
    "chemin2 = \"data/{}/gensim/dim{}_ep{}_w{}_lr{}_seed5\".format(nom_dossier, dim, epoch, window, str(learning_rate)[2:])  \n",
    "model2 = gensim.models.keyedvectors.KeyedVectors.load(chemin2 + \"/word2vec.model\")\n",
    "chemin3 = \"data/{}/gensim/dim{}_ep{}_w{}_lr{}_seed10\".format(nom_dossier, dim, epoch, window, str(learning_rate)[2:])  \n",
    "model3 = gensim.models.keyedvectors.KeyedVectors.load(chemin3 + \"/word2vec.model\")\n",
    "chemin4 = \"data/{}/gensim/dim{}_ep{}_w{}_lr{}_seed15\".format(nom_dossier, dim, epoch, window, str(learning_rate)[2:])  \n",
    "model4 = gensim.models.keyedvectors.KeyedVectors.load(chemin4 + \"/word2vec.model\")\n",
    "chemin5 = \"data/{}/gensim/dim{}_ep{}_w{}_lr{}_seed20\".format(nom_dossier, dim, epoch, window, str(learning_rate)[2:])  \n",
    "model5 = gensim.models.keyedvectors.KeyedVectors.load(chemin5 + \"/word2vec.model\")\n",
    "chemin6 = \"data/{}/gensim/dim{}_ep{}_w{}_lr{}_seed25\".format(nom_dossier, dim, epoch, window, str(learning_rate)[2:]) \n",
    "model6 = gensim.models.keyedvectors.KeyedVectors.load(chemin6 + \"/word2vec.model\")\n",
    "\n",
    "matrice = {word : (model1.wv[word]+model2.wv[word]+model3.wv[word]+model4.wv[word]+model5.wv[word]+model6.wv[word])/6\n",
    "           for word in model1.wv.index2word}\n",
    "\n",
    "def normalize(v):\n",
    "    norm = np.linalg.norm(v)\n",
    "    if norm == 0: \n",
    "        return v\n",
    "    return v / norm\n",
    "\n",
    "matrice_norm = {word : normalize(matrice[word]) for word in matrice.keys()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrases = [[tweet.split(),score] for (score, tweet) in corpus_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrases_emb = [[score,calcul_sentence_embedding(phrase)] for (phrase,score) in phrases]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = [score for (score, embedding) in phrases_emb]\n",
    "X_train = [embedding for (score, embedding) in phrases_emb]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression()\n",
    "reg_log = lr.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7359 1821]\n",
      " [2965 3859]]\n",
      "0.7009497625593601\n"
     ]
    }
   ],
   "source": [
    "Y_train_pred = reg_log.predict(X_train)\n",
    "\n",
    "from sklearn import metrics\n",
    "# Matrice confusion\n",
    "cm = metrics.confusion_matrix(Y_train,Y_train_pred)\n",
    "print(cm)\n",
    "# Accuracy\n",
    "acc = metrics.accuracy_score(Y_train,Y_train_pred)\n",
    "print(acc) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrases_test = [[tweet.split(),score] for (score, tweet) in corpus_test]\n",
    "phrases_test_emb = [[score,calcul_sentence_embedding(phrase)] for (phrase,score) in phrases_test]\n",
    "Y_test = [score for (score, embedding) in phrases_test_emb]\n",
    "X_test = [embedding for (score, embedding) in phrases_test_emb]\n",
    "Y_test_pred = reg_log.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3125  809]\n",
      " [1263 1661]]\n",
      "0.6978710994459026\n"
     ]
    }
   ],
   "source": [
    "# Matrice confusion\n",
    "cm_test = metrics.confusion_matrix(Y_test,Y_test_pred)\n",
    "print(cm_test)\n",
    "# Accuracy\n",
    "acc_test = metrics.accuracy_score(Y_test,Y_test_pred)\n",
    "print(acc_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Si on veut récup les fichiers\n",
    "with open(\"data/sentimental_analysis/corpus_test.file\", \"rb\") as f:\n",
    "    corpus_test_git = pickle.load(f)\n",
    "with open(\"data/sentimental_analysis/corpus_train.file\", \"rb\") as f:\n",
    "    corpus_train_git = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrases = [[tweet.split(),score] for (score, tweet) in corpus_train_git]\n",
    "phrases_emb = [[score,calcul_sentence_embedding(phrase)] for (phrase,score) in phrases]\n",
    "Y_train_git = [score for (score, embedding) in phrases_emb]\n",
    "X_train_git = [embedding for (score, embedding) in phrases_emb]\n",
    "\n",
    "phrases_test = [[tweet.split(),score] for (score, tweet) in corpus_test_git]\n",
    "phrases_test_emb = [[score,calcul_sentence_embedding(phrase)] for (phrase,score) in phrases_test]\n",
    "Y_test_git = [score for (score, embedding) in phrases_test_emb]\n",
    "X_test_git = [embedding for (score, embedding) in phrases_test_emb]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 951 1033]\n",
      " [ 485 1513]]\n",
      "0.6187845303867403\n"
     ]
    }
   ],
   "source": [
    "Y_test_git_pred = reg_log.predict(X_test_git)\n",
    "# Matrice confusion\n",
    "cm_test = metrics.confusion_matrix(Y_test_git,Y_test_git_pred)\n",
    "print(cm_test)\n",
    "# Accuracy\n",
    "acc_test = metrics.accuracy_score(Y_test_git,Y_test_git_pred)\n",
    "print(acc_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[17577  7423]\n",
      " [ 7983 17017]]\n",
      "0.69188\n"
     ]
    }
   ],
   "source": [
    "reg_log_git = lr.fit(X_train_git,Y_train_git)\n",
    "Y_train_git_pred = reg_log_git.predict(X_train_git)\n",
    "\n",
    "from sklearn import metrics\n",
    "# Matrice confusion\n",
    "cm = metrics.confusion_matrix(Y_train_git,Y_train_git_pred)\n",
    "print(cm)\n",
    "# Accuracy\n",
    "acc = metrics.accuracy_score(Y_train_git,Y_train_git_pred)\n",
    "print(acc) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1399  585]\n",
      " [ 661 1337]]\n",
      "0.6870919136112507\n"
     ]
    }
   ],
   "source": [
    "Y_test_git_pred = reg_log_git.predict(X_test_git)\n",
    "# Matrice confusion\n",
    "cm_test = metrics.confusion_matrix(Y_test_git,Y_test_git_pred)\n",
    "print(cm_test)\n",
    "# Accuracy\n",
    "acc_test = metrics.accuracy_score(Y_test_git,Y_test_git_pred)\n",
    "print(acc_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3357  577]\n",
      " [1946  978]]\n",
      "0.6321084864391951\n"
     ]
    }
   ],
   "source": [
    "Y_test_pred = reg_log_git.predict(X_test)\n",
    "# Matrice confusion\n",
    "cm_test = metrics.confusion_matrix(Y_test,Y_test_pred)\n",
    "print(cm_test)\n",
    "# Accuracy\n",
    "acc_test = metrics.accuracy_score(Y_test,Y_test_pred)\n",
    "print(acc_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/sentimental_analysis/reg_log_sncf.file\", \"wb\") as f:\n",
    "    pickle.dump(reg_log, f, pickle.HIGHEST_PROTOCOL)\n",
    "with open(\"data/sentimental_analysis/reg_log_git.file\", \"wb\") as f:\n",
    "    pickle.dump(reg_log_git, f, pickle.HIGHEST_PROTOCOL)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
