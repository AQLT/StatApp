{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Début d'implémentation du modèle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Étape 0 : Importations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Étape 1 : Récupération des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"C:/Users/torna/Documents/StatApp/StatApp/data/sample1.txt\",sep='\\n',header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Étape 2 : Créer le vocabulaire à partir du corpus de phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df[0:100]\n",
    "\n",
    "corpus = []\n",
    "for index, row in df2.iterrows():\n",
    "    for j, column in row.iteritems():\n",
    "        corpus.append(column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_corr = []\n",
    "\n",
    "for phrase in corpus:\n",
    "    # Suppression de la ponctuation\n",
    "    phrase = phrase.replace(\"?\",\"\")\n",
    "    phrase = phrase.replace(\".\",\"\")\n",
    "    phrase = phrase.replace(\"!\",\"\")\n",
    "    phrase = phrase.replace(\";\",\"\")\n",
    "    phrase = phrase.replace(\",\",\"\")\n",
    "    phrase = phrase.replace(\":\",\"\")\n",
    "    phrase = phrase.replace(\"#\",\"\")\n",
    "    # On met tout en minuscule\n",
    "    phrase = phrase.lower()\n",
    "    # On ajoute la phrase\n",
    "    corpus_corr.append(phrase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(corpus):\n",
    "    tokens = [phrase.split() for phrase in corpus]\n",
    "    return tokens\n",
    "\n",
    "t_corpus = tokenize(corpus_corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On supprime les mentions @nicknames\n",
    "corpus_ok = []\n",
    "for phrase in t_corpus:\n",
    "    phrase_bis = []\n",
    "    for mot in phrase:\n",
    "        if mot[0] == '@':\n",
    "            mot = \"nickname\"\n",
    "        phrase_bis.append(mot)\n",
    "    corpus_ok.append(phrase_bis)\n",
    "t_corpus = corpus_ok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "524\n"
     ]
    }
   ],
   "source": [
    "voc = []\n",
    "freqs = {}\n",
    "for phrase in t_corpus:\n",
    "    for mot in phrase:\n",
    "        if mot not in voc:\n",
    "            voc.append(mot)\n",
    "            freqs[mot] = 1\n",
    "        else:\n",
    "            freqs[mot] +=1\n",
    "voc_size = len(voc)\n",
    "print(voc_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Calcul des probas pour le subsampling et le negative sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_mots = 0\n",
    "for phrase in t_corpus:\n",
    "    total_mots += len(phrase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in freqs.items():\n",
    "    freqs[key] = value / total_mots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'slice'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-34-3c6d0ecc7d79>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Probabilité d'être gardé dans le subsampling\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mp_sub\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfreqs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m0.001\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.001\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mfreqs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfreqs\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mp_sub\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: unhashable type: 'slice'"
     ]
    }
   ],
   "source": [
    "# Probabilité d'être gardé dans le subsampling\n",
    "p_sub = {word: min((math.sqrt(freqs[word]/0.001)+1)*(0.001/freqs[word]),1) for word in freqs}\n",
    "p_sub[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'il': 0.009753021158773238,\n",
       " 'mérite': 0.0011649370968134988,\n",
       " 'd’': 0.002655482333094781,\n",
       " 'être': 0.003294939683250378,\n",
       " 'bloquer': 0.0011649370968134988,\n",
       " 'la': 0.007510838260209577,\n",
       " 'lettre': 0.0011649370968134988,\n",
       " 'de': 0.017121008817793677,\n",
       " 'l’': 0.003294939683250378,\n",
       " 'alphabet': 0.0011649370968134988,\n",
       " '@reinedonna': 0.0011649370968134988,\n",
       " 'et': 0.006053190717908292,\n",
       " 'fière': 0.0011649370968134988,\n",
       " 'je': 0.008879140326466525,\n",
       " \"t'\": 0.003294939683250378,\n",
       " \"en'\": 0.0011649370968134988,\n",
       " 'voi': 0.0011649370968134988,\n",
       " 'att': 0.0011649370968134988,\n",
       " \"j'\": 0.005013326682380654,\n",
       " 'avais': 0.0011649370968134988,\n",
       " 'oublié': 0.0011649370968134988,\n",
       " 'est': 0.014557975152459027,\n",
       " '1': 0.002655482333094781,\n",
       " 'heure': 0.001959182857413081,\n",
       " 'eeeeh': 0.0011649370968134988,\n",
       " 'jfais': 0.0011649370968134988,\n",
       " 'go': 0.003294939683250378,\n",
       " 'qui': 0.003895201947007034,\n",
       " 'a': 0.006550922707855008,\n",
       " 'les': 0.008431376871419378,\n",
       " 'programmes': 0.0011649370968134988,\n",
       " 'mais': 0.003895201947007034,\n",
       " 'j’': 0.006550922707855008,\n",
       " 'ai': 0.002655482333094781,\n",
       " 'même': 0.003294939683250378,\n",
       " 'pas': 0.011427913551306382,\n",
       " 'navigo': 0.0011649370968134988,\n",
       " 'ptdddddr': 0.0011649370968134988,\n",
       " '😭': 0.003895201947007034,\n",
       " 'en': 0.008879140326466525,\n",
       " 'tout': 0.001959182857413081,\n",
       " 'cas': 0.0011649370968134988,\n",
       " 'demoiselle': 0.0011649370968134988,\n",
       " 'bien': 0.001959182857413081,\n",
       " 'raison': 0.0011649370968134988,\n",
       " 'le': 0.01223484163682096,\n",
       " 'rathalos': 0.0011649370968134988,\n",
       " 'un': 0.006053190717908292,\n",
       " 'gros': 0.002655482333094781,\n",
       " 'fils': 0.0011649370968134988,\n",
       " 'pute': 0.0011649370968134988,\n",
       " 'bonne': 0.002655482333094781,\n",
       " 'nuit': 0.002655482333094781,\n",
       " '@stephanielevy75': 0.0011649370968134988,\n",
       " 'puis': 0.0011649370968134988,\n",
       " 'jour': 0.0011649370968134988,\n",
       " 'pfffffffffus': 0.0011649370968134988,\n",
       " 'rien': 0.002655482333094781,\n",
       " 'ne': 0.002655482333094781,\n",
       " 'fonctionne': 0.0011649370968134988,\n",
       " 'humain': 0.0011649370968134988,\n",
       " 'se': 0.002655482333094781,\n",
       " 'meurt': 0.0011649370968134988,\n",
       " 'à': 0.011427913551306382,\n",
       " 'petit': 0.0011649370968134988,\n",
       " 'feu': 0.0011649370968134988,\n",
       " '@rebeudeter': 0.0011649370968134988,\n",
       " 'veux': 0.002655482333094781,\n",
       " '+': 0.0011649370968134988,\n",
       " 'savoir': 0.0011649370968134988,\n",
       " 'sasuke': 0.0011649370968134988,\n",
       " '(': 0.001959182857413081,\n",
       " 'sais': 0.001959182857413081,\n",
       " 'c’': 0.007510838260209577,\n",
       " 'crois': 0.001959182857413081,\n",
       " 'sombre': 0.0011649370968134988,\n",
       " ')': 0.001959182857413081,\n",
       " 'partir': 0.0011649370968134988,\n",
       " 'quand': 0.002655482333094781,\n",
       " 'peut': 0.001959182857413081,\n",
       " '-on': 0.0011649370968134988,\n",
       " 'qualifier': 0.0011649370968134988,\n",
       " 'fan': 0.0011649370968134988,\n",
       " 'profité': 0.001959182857413081,\n",
       " '6h20': 0.0011649370968134988,\n",
       " 'sommeil': 0.0011649370968134988,\n",
       " \"qu'\": 0.001959182857413081,\n",
       " 'me': 0.006053190717908292,\n",
       " 'reste': 0.0011649370968134988,\n",
       " '@omgitsfsk': 0.0011649370968134988,\n",
       " 'merci': 0.003294939683250378,\n",
       " 'frere': 0.0011649370968134988,\n",
       " '@calumsokitten': 0.0011649370968134988,\n",
       " 'pendant': 0.0011649370968134988,\n",
       " 'examens': 0.0011649370968134988,\n",
       " 'suis': 0.003895201947007034,\n",
       " 'vizir': 0.0011649370968134988,\n",
       " 'mélo': 0.0011649370968134988,\n",
       " 'loli': 0.0011649370968134988,\n",
       " '@saarahxm': 0.0011649370968134988,\n",
       " 't': 0.0011649370968134988,\n",
       " 'vraiment': 0.003294939683250378,\n",
       " 'une': 0.005013326682380654,\n",
       " 'menteuse': 0.0011649370968134988,\n",
       " 'hilarante': 0.0011649370968134988,\n",
       " 'comme': 0.003294939683250378,\n",
       " 'meuf': 0.001959182857413081,\n",
       " 'ça': 0.006550922707855008,\n",
       " 'première': 0.0011649370968134988,\n",
       " 'fois': 0.001959182857413081,\n",
       " 'que': 0.00931949677450799,\n",
       " 'tu': 0.008879140326466525,\n",
       " 'ris': 0.0011649370968134988,\n",
       " 'hé': 0.0011649370968134988,\n",
       " 'rapido': 0.0011649370968134988,\n",
       " 'son': 0.001959182857413081,\n",
       " 'odeur': 0.0011649370968134988,\n",
       " 'dans': 0.002655482333094781,\n",
       " 'lit': 0.0011649370968134988,\n",
       " 'ptn': 0.0011649370968134988,\n",
       " 'quoi': 0.002655482333094781,\n",
       " 'cette': 0.0011649370968134988,\n",
       " 'souffrance': 0.0011649370968134988,\n",
       " '5': 0.001959182857413081,\n",
       " 'mois': 0.001959182857413081,\n",
       " 'passé': 0.0011649370968134988,\n",
       " 'moyenne': 0.0011649370968134988,\n",
       " 'sur': 0.003294939683250378,\n",
       " 'applis': 0.0011649370968134988,\n",
       " '2017': 0.0011649370968134988,\n",
       " '@faz_m10': 0.0011649370968134988,\n",
       " '@sylvainlapince': 0.0011649370968134988,\n",
       " 'pnl': 0.0011649370968134988,\n",
       " 'niska': 0.0011649370968134988,\n",
       " \"c'\": 0.007036342796162277,\n",
       " 'clairement': 0.0011649370968134988,\n",
       " '-': 0.0011649370968134988,\n",
       " 'dessus': 0.0011649370968134988,\n",
       " 'lui': 0.002655482333094781,\n",
       " '@badgyalbobi': 0.0011649370968134988,\n",
       " 'te': 0.001959182857413081,\n",
       " 'jure': 0.0011649370968134988,\n",
       " \"n'\": 0.0011649370968134988,\n",
       " 'importe': 0.0011649370968134988,\n",
       " '☹': 0.0011649370968134988,\n",
       " '@shikamarias': 0.0011649370968134988,\n",
       " 'dropou': 0.0011649370968134988,\n",
       " 'o': 0.0011649370968134988,\n",
       " 'kpop': 0.0011649370968134988,\n",
       " '@vinsouu': 0.0011649370968134988,\n",
       " 'ouais': 0.0011649370968134988,\n",
       " 'dirais': 0.0011649370968134988,\n",
       " 'ce': 0.005013326682380654,\n",
       " 'fut': 0.0011649370968134988,\n",
       " 'énorme': 0.0011649370968134988,\n",
       " 'échec': 0.0011649370968134988,\n",
       " 'on': 0.004465971149337944,\n",
       " 'février': 0.0011649370968134988,\n",
       " '@pnl': 0.0011649370968134988,\n",
       " 'music': 0.0011649370968134988,\n",
       " 'sont': 0.001959182857413081,\n",
       " 'toujours': 0.001959182857413081,\n",
       " 'mort': 0.001959182857413081,\n",
       " 'demanderait': 0.0011649370968134988,\n",
       " 'choisir': 0.0011649370968134988,\n",
       " 'entre': 0.0011649370968134988,\n",
       " 'manger': 0.001959182857413081,\n",
       " 'coudre': 0.0011649370968134988,\n",
       " 'si': 0.002655482333094781,\n",
       " 'n’': 0.0011649370968134988,\n",
       " 'étais': 0.0011649370968134988,\n",
       " 'besoin': 0.0011649370968134988,\n",
       " 'vital': 0.0011649370968134988,\n",
       " 'mdr': 0.0011649370968134988,\n",
       " 'bah': 0.001959182857413081,\n",
       " 'choisirait': 0.0011649370968134988,\n",
       " '1000': 0.0011649370968134988,\n",
       " 'couture': 0.0011649370968134988,\n",
       " 'vie': 0.002655482333094781,\n",
       " 'ma': 0.004465971149337944,\n",
       " 'mère': 0.001959182857413081,\n",
       " '11': 0.0011649370968134988,\n",
       " 'septembre': 0.0011649370968134988,\n",
       " 'était': 0.003895201947007034,\n",
       " 'orchestré': 0.0011649370968134988,\n",
       " 'par': 0.002655482333094781,\n",
       " 'américains': 0.0011649370968134988,\n",
       " 'trouvais': 0.0011649370968134988,\n",
       " 'mon': 0.002655482333094781,\n",
       " 'doudou': 0.0011649370968134988,\n",
       " 'pour': 0.005013326682380654,\n",
       " 'dodo': 0.0011649370968134988,\n",
       " 'comment': 0.001959182857413081,\n",
       " 'jouant': 0.0011649370968134988,\n",
       " 'jamais': 0.001959182857413081,\n",
       " 'giroud': 0.0011649370968134988,\n",
       " 'pu': 0.001959182857413081,\n",
       " 'passer': 0.0011649370968134988,\n",
       " 'arsenal': 0.0011649370968134988,\n",
       " 'chelsea': 0.0011649370968134988,\n",
       " '@hunifnt': 0.0011649370968134988,\n",
       " 'vérité': 0.001959182857413081,\n",
       " 'bout': 0.0011649370968134988,\n",
       " '@bloodysusu': 0.0011649370968134988,\n",
       " '@personnecsgo': 0.0011649370968134988,\n",
       " 'bloody': 0.0011649370968134988,\n",
       " '@akamevil': 0.0011649370968134988,\n",
       " 'jspr': 0.0011649370968134988,\n",
       " 'tt': 0.001959182857413081,\n",
       " 'coeur': 0.0011649370968134988,\n",
       " 'vas': 0.0011649370968134988,\n",
       " 'faire': 0.002655482333094781,\n",
       " 'insulter': 0.001959182857413081,\n",
       " 'lmonde': 0.0011649370968134988,\n",
       " '@lisang': 0.0011649370968134988,\n",
       " 'inquisition': 0.0011649370968134988,\n",
       " '@araguanick_': 0.0011649370968134988,\n",
       " 'sa': 0.003294939683250378,\n",
       " 'glisse': 0.0011649370968134988,\n",
       " 'normal': 0.0011649370968134988,\n",
       " 'pire': 0.001959182857413081,\n",
       " 'wallah': 0.001959182857413081,\n",
       " '@chtruchet': 0.0011649370968134988,\n",
       " '@oliberne': 0.0011649370968134988,\n",
       " 'chercheur': 0.0011649370968134988,\n",
       " 'disruptif': 0.0011649370968134988,\n",
       " 'es': 0.003294939683250378,\n",
       " 'fleuron': 0.0011649370968134988,\n",
       " '@realunivfrance': 0.0011649370968134988,\n",
       " '@sapriisti': 0.001959182857413081,\n",
       " '@rizta__': 0.0011649370968134988,\n",
       " 'parle': 0.0011649370968134988,\n",
       " 'aussi': 0.002655482333094781,\n",
       " 'ahah': 0.001959182857413081,\n",
       " '@angelotipster': 0.0011649370968134988,\n",
       " 'gro': 0.0011649370968134988,\n",
       " 'xbox': 0.0011649370968134988,\n",
       " 'onze': 0.0011649370968134988,\n",
       " '@tenshihiime': 0.0011649370968134988,\n",
       " 'muret': 0.0011649370968134988,\n",
       " 'wesh': 0.0011649370968134988,\n",
       " 'mur': 0.001959182857413081,\n",
       " 'fait': 0.0011649370968134988,\n",
       " 'mètres': 0.0011649370968134988,\n",
       " '@dieumichet': 0.0011649370968134988,\n",
       " 'tenait': 0.0011649370968134988,\n",
       " '«': 0.002655482333094781,\n",
       " '»': 0.002655482333094781,\n",
       " '🤔': 0.001959182857413081,\n",
       " '🤓': 0.0011649370968134988,\n",
       " 'pensé': 0.0011649370968134988,\n",
       " '1h': 0.001959182857413081,\n",
       " 'mat': 0.001959182857413081,\n",
       " '’': 0.0011649370968134988,\n",
       " 'afida': 0.0011649370968134988,\n",
       " 'turner': 0.0011649370968134988,\n",
       " 'elle': 0.001959182857413081,\n",
       " 'dégueulasse': 0.0011649370968134988,\n",
       " 'mdrrr': 0.002655482333094781,\n",
       " '@20h42min': 0.0011649370968134988,\n",
       " 'jte': 0.0011649370968134988,\n",
       " 'laisse': 0.0011649370968134988,\n",
       " 'seule': 0.001959182857413081,\n",
       " 'seconde': 0.0011649370968134988,\n",
       " 'c': 0.003294939683250378,\n",
       " 'clair': 0.0011649370968134988,\n",
       " 'chu': 0.0011649370968134988,\n",
       " 'sang': 0.0011649370968134988,\n",
       " 'pr': 0.0011649370968134988,\n",
       " 'toi': 0.003294939683250378,\n",
       " '@misterb_01': 0.0011649370968134988,\n",
       " 'experience': 0.0011649370968134988,\n",
       " 'vs': 0.001959182857413081,\n",
       " 'nouveau': 0.001959182857413081,\n",
       " 'riche': 0.0011649370968134988,\n",
       " '😜': 0.0011649370968134988,\n",
       " 'celtes': 0.0011649370968134988,\n",
       " 'faite': 0.0011649370968134988,\n",
       " '@romainbgb': 0.0011649370968134988,\n",
       " 'mouais': 0.0011649370968134988,\n",
       " 'tôt': 0.0011649370968134988,\n",
       " 'tellement': 0.0011649370968134988,\n",
       " 'qu’': 0.0011649370968134988,\n",
       " 'ils': 0.0011649370968134988,\n",
       " 'ont': 0.0011649370968134988,\n",
       " 'clippe': 0.0011649370968134988,\n",
       " '@kaddddddd': 0.0011649370968134988,\n",
       " 'aime': 0.0011649370968134988,\n",
       " 'kad': 0.0011649370968134988,\n",
       " '🤤': 0.0011649370968134988,\n",
       " 'déchaîné': 0.0011649370968134988,\n",
       " 'trooooop': 0.0011649370968134988,\n",
       " '@bobsaintjacques': 0.0011649370968134988,\n",
       " 'bonsoir': 0.0011649370968134988,\n",
       " 'cher': 0.0011649370968134988,\n",
       " 'bob': 0.0011649370968134988,\n",
       " '*j’': 0.0011649370968134988,\n",
       " 'peux': 0.0011649370968134988,\n",
       " '@meltdownparis': 0.0011649370968134988,\n",
       " '@bestmarmotte': 0.0011649370968134988,\n",
       " 'rappelle': 0.0011649370968134988,\n",
       " 'soirée': 0.0011649370968134988,\n",
       " 'discord': 0.0011649370968134988,\n",
       " '😊': 0.0011649370968134988,\n",
       " 'espère': 0.0011649370968134988,\n",
       " 'vous': 0.003895201947007034,\n",
       " 'avez': 0.0011649370968134988,\n",
       " '@zetepneudaemon': 0.0011649370968134988,\n",
       " '@krisq3011': 0.0011649370968134988,\n",
       " 'jou': 0.0011649370968134988,\n",
       " 'lou': 0.0011649370968134988,\n",
       " 'coumpren': 0.0011649370968134988,\n",
       " 'dakour': 0.0011649370968134988,\n",
       " 'msiou': 0.0011649370968134988,\n",
       " \"s'\": 0.0011649370968134988,\n",
       " 'plaît': 0.0011649370968134988,\n",
       " 'ourvoir': 0.0011649370968134988,\n",
       " 'disouli': 0.0011649370968134988,\n",
       " 'attendre': 0.0011649370968134988,\n",
       " 'cinq': 0.0011649370968134988,\n",
       " 'enfin': 0.0011649370968134988,\n",
       " 'apprécier': 0.0011649370968134988,\n",
       " 'coloc': 0.0011649370968134988,\n",
       " '✅': 0.0011649370968134988,\n",
       " 'pourquoi': 0.001959182857413081,\n",
       " 'thé': 0.0011649370968134988,\n",
       " 'doux': 0.0011649370968134988,\n",
       " '☺': 0.0011649370968134988,\n",
       " '️': 0.0011649370968134988,\n",
       " '😋': 0.0011649370968134988,\n",
       " '@rulebavaria': 0.0011649370968134988,\n",
       " 'devrais': 0.0011649370968134988,\n",
       " 'avait': 0.0011649370968134988,\n",
       " 'parlé': 0.0011649370968134988,\n",
       " 'déjà': 0.001959182857413081,\n",
       " 'formidable': 0.0011649370968134988,\n",
       " 'bouquin': 0.0011649370968134988,\n",
       " '@t88stark': 0.0011649370968134988,\n",
       " 'reve': 0.0011649370968134988,\n",
       " \"l'\": 0.0011649370968134988,\n",
       " 'encastrer': 0.0011649370968134988,\n",
       " 'gars': 0.0011649370968134988,\n",
       " 'cet': 0.0011649370968134988,\n",
       " 'été': 0.0011649370968134988,\n",
       " 'inventait': 0.0011649370968134988,\n",
       " 'transferts': 0.0011649370968134988,\n",
       " 'avec': 0.003294939683250378,\n",
       " 'infos': 0.0011649370968134988,\n",
       " 'fake': 0.0011649370968134988,\n",
       " 'va': 0.001959182857413081,\n",
       " '@flo_raison': 0.0011649370968134988,\n",
       " 'convaincu': 0.0011649370968134988,\n",
       " 'tes': 0.0011649370968134988,\n",
       " 'arguments': 0.0011649370968134988,\n",
       " 'y': 0.0011649370968134988,\n",
       " 'qd-': 0.0011649370968134988,\n",
       " 'million': 0.0011649370968134988,\n",
       " \"d'\": 0.001959182857413081,\n",
       " 'euros': 0.0011649370968134988,\n",
       " 'pose': 0.0011649370968134988,\n",
       " 'question': 0.0011649370968134988,\n",
       " 'contexte': 0.0011649370968134988,\n",
       " '@dremar66': 0.0011649370968134988,\n",
       " 'faut': 0.001959182857413081,\n",
       " 'virer': 0.0011649370968134988,\n",
       " 'ah': 0.001959182857413081,\n",
       " 'oubliais': 0.0011649370968134988,\n",
       " 'soirées': 0.0011649370968134988,\n",
       " 'etc': 0.0011649370968134988,\n",
       " '@jroule1teh': 0.0011649370968134988,\n",
       " 'moi': 0.002655482333094781,\n",
       " 'mtue': 0.0011649370968134988,\n",
       " 'mle': 0.0011649370968134988,\n",
       " 'dit': 0.0011649370968134988,\n",
       " '@agnieszkaa_m': 0.0011649370968134988,\n",
       " 'comprendras': 0.0011649370968134988,\n",
       " 'pense': 0.001959182857413081,\n",
       " 'auras': 0.0011649370968134988,\n",
       " 'envie': 0.0011649370968134988,\n",
       " \"m'\": 0.0011649370968134988,\n",
       " 'étriper': 0.0011649370968134988,\n",
       " 'coup': 0.0011649370968134988,\n",
       " 'crêpes': 0.0011649370968134988,\n",
       " 'inch': 0.0011649370968134988,\n",
       " 'réveille': 0.0011649370968134988,\n",
       " 'tuer': 0.0011649370968134988,\n",
       " 'demandée': 0.0011649370968134988,\n",
       " 'début': 0.0011649370968134988,\n",
       " 'ptdr': 0.002655482333094781,\n",
       " 'lrt': 0.0011649370968134988,\n",
       " 'kayode': 0.0011649370968134988,\n",
       " 'girona': 0.0011649370968134988,\n",
       " 'signe': 0.0011649370968134988,\n",
       " 'amiens': 0.0011649370968134988,\n",
       " 'voir': 0.0011649370968134988,\n",
       " 'liga': 0.0011649370968134988,\n",
       " 'mauvaise': 0.0011649370968134988,\n",
       " 'pioche': 0.0011649370968134988,\n",
       " 'picards': 0.0011649370968134988,\n",
       " 'arrive': 0.0011649370968134988,\n",
       " 'dormir': 0.002655482333094781,\n",
       " '@kelluuxx': 0.0011649370968134988,\n",
       " 'mddddr': 0.0011649370968134988,\n",
       " 'mskn': 0.0011649370968134988,\n",
       " 'handicapé': 0.0011649370968134988,\n",
       " 'demander': 0.0011649370968134988,\n",
       " 'personne': 0.002655482333094781,\n",
       " '@mbrr16': 0.0011649370968134988,\n",
       " 'parce': 0.001959182857413081,\n",
       " 'gouter': 0.0011649370968134988,\n",
       " 'ceux': 0.0011649370968134988,\n",
       " 'carrefour': 0.0011649370968134988,\n",
       " 'tuerie': 0.0011649370968134988,\n",
       " 'yesssss': 0.0011649370968134988,\n",
       " 'fevrier': 0.0011649370968134988,\n",
       " '2018': 0.0011649370968134988,\n",
       " 'aimerai': 0.0011649370968134988,\n",
       " 'là': 0.002655482333094781,\n",
       " 'aurélien': 0.0011649370968134988,\n",
       " 'zap': 0.0011649370968134988,\n",
       " 'bcp': 0.0011649370968134988,\n",
       " 'moment': 0.0011649370968134988,\n",
       " 'plais': 0.0011649370968134988,\n",
       " 'carrément': 0.0011649370968134988,\n",
       " 'après': 0.0011649370968134988,\n",
       " 'tord': 0.0011649370968134988,\n",
       " '100': 0.0011649370968134988,\n",
       " '%': 0.0011649370968134988,\n",
       " 'pck': 0.0011649370968134988,\n",
       " 'premier': 0.0011649370968134988,\n",
       " 'dire': 0.001959182857413081,\n",
       " 'pouvez': 0.0011649370968134988,\n",
       " 'm’': 0.001959182857413081,\n",
       " 'parler': 0.001959182857413081,\n",
       " 'voulez': 0.0011649370968134988,\n",
       " 'atteint': 0.0011649370968134988,\n",
       " '@kirby_j92': 0.0011649370968134988,\n",
       " 'non': 0.0011649370968134988,\n",
       " 'jeu': 0.0011649370968134988,\n",
       " 'random': 0.0011649370968134988,\n",
       " '@justdiamant': 0.0011649370968134988,\n",
       " 'gage': 0.0011649370968134988,\n",
       " 'qualité': 0.0011649370968134988,\n",
       " '👌': 0.0011649370968134988,\n",
       " '@acarreprod': 0.0011649370968134988,\n",
       " 'kira': 0.0011649370968134988,\n",
       " 'tfacon': 0.0011649370968134988,\n",
       " 'écouter': 0.0011649370968134988,\n",
       " 'aznavour': 0.0011649370968134988,\n",
       " 'beau': 0.0011649370968134988,\n",
       " 'dernière': 0.0011649370968134988,\n",
       " 'grosse': 0.0011649370968134988,\n",
       " 'session': 0.0011649370968134988,\n",
       " 'exams': 0.0011649370968134988,\n",
       " 'arrêtez': 0.0011649370968134988,\n",
       " 'dvou': 0.0011649370968134988,\n",
       " 'batt': 0.0011649370968134988,\n",
       " 'tl': 0.0011649370968134988,\n",
       " '@palgorythme': 0.0011649370968134988,\n",
       " '@bouldure': 0.0011649370968134988,\n",
       " '@rubar_beuh': 0.0011649370968134988,\n",
       " '@izeut_qc': 0.0011649370968134988,\n",
       " '@frederic_molas': 0.0011649370968134988,\n",
       " '@gpetrazzo': 0.0011649370968134988,\n",
       " '@fandomgrenier': 0.0011649370968134988,\n",
       " '@histoirebreve': 0.0011649370968134988,\n",
       " 'ca': 0.0011649370968134988,\n",
       " 'vais': 0.0011649370968134988,\n",
       " 'devenir': 0.0011649370968134988,\n",
       " 'mec': 0.0011649370968134988,\n",
       " 'sans': 0.0011649370968134988,\n",
       " 'cœur': 0.001959182857413081,\n",
       " 'rigole': 0.0011649370968134988,\n",
       " 'plus': 0.0011649370968134988,\n",
       " 'fini': 0.0011649370968134988,\n",
       " 'gentil': 0.0011649370968134988,\n",
       " 'sah': 0.0011649370968134988,\n",
       " 'suivre': 0.0011649370968134988,\n",
       " 'réseaux': 0.0011649370968134988,\n",
       " 'veut': 0.0011649370968134988,\n",
       " 'tant': 0.0011649370968134988,\n",
       " 'cherches': 0.0011649370968134988,\n",
       " 'source': 0.0011649370968134988,\n",
       " 'problèmes': 0.0011649370968134988,\n",
       " 'offrez': 0.0011649370968134988,\n",
       " 'stickers': 0.0011649370968134988,\n",
       " 'mignons': 0.0011649370968134988,\n",
       " 'allez': 0.0011649370968134988,\n",
       " 'gagner': 0.0011649370968134988,\n",
       " '@anthoinkazo': 0.0011649370968134988,\n",
       " 'demande': 0.0011649370968134988,\n",
       " '10': 0.0011649370968134988,\n",
       " 'miliar': 0.0011649370968134988,\n",
       " 'chien': 0.0011649370968134988,\n",
       " '@fratepoverello': 0.0011649370968134988,\n",
       " 'trop': 0.0011649370968134988,\n",
       " 'aimable': 0.0011649370968134988,\n",
       " '@baro93tuconnais': 0.0011649370968134988,\n",
       " 'soul': 0.0011649370968134988,\n",
       " '@naracedric': 0.0011649370968134988,\n",
       " 'ptdrrrr': 0.0011649370968134988,\n",
       " 'cest': 0.0011649370968134988,\n",
       " 'rick': 0.0011649370968134988,\n",
       " '0101': 0.0011649370968134988,\n",
       " 'claude': 0.0011649370968134988,\n",
       " 'jtm': 0.0011649370968134988,\n",
       " 'tiakola': 0.0011649370968134988,\n",
       " 'très': 0.001959182857413081,\n",
       " 'bon': 0.001959182857413081,\n",
       " '@dydydz': 0.0011649370968134988,\n",
       " 'nn': 0.0011649370968134988,\n",
       " 'dangereux': 0.0011649370968134988,\n",
       " 'tjr': 0.0011649370968134988,\n",
       " 'montrer': 0.0011649370968134988,\n",
       " 'ta': 0.001959182857413081,\n",
       " 'tête': 0.0011649370968134988,\n",
       " 'peuple': 0.0011649370968134988,\n",
       " 'jvais': 0.001959182857413081,\n",
       " 'aller': 0.0011649370968134988,\n",
       " 'sinon': 0.0011649370968134988,\n",
       " 'lever': 0.0011649370968134988,\n",
       " 'demain': 0.0011649370968134988,\n",
       " 'ns': 0.0011649370968134988,\n",
       " 'sommes': 0.0011649370968134988,\n",
       " '2': 0.0011649370968134988,\n",
       " 'semaines': 0.0011649370968134988,\n",
       " 'match': 0.0011649370968134988,\n",
       " 'psg': 0.0011649370968134988,\n",
       " 'réal': 0.0011649370968134988,\n",
       " 'restez': 0.0011649370968134988,\n",
       " 'concentré': 0.0011649370968134988,\n",
       " 'tous': 0.0011649370968134988,\n",
       " 'sauf': 0.0011649370968134988,\n",
       " 'pourtant': 0.0011649370968134988,\n",
       " 'jsuis': 0.0011649370968134988,\n",
       " 'grave': 0.0011649370968134988,\n",
       " 'épuisé': 0.0011649370968134988,\n",
       " '😩': 0.0011649370968134988,\n",
       " '@serenel14278447': 0.0011649370968134988,\n",
       " 'sere': 0.0011649370968134988,\n",
       " 'amie': 0.0011649370968134988,\n",
       " 'italienne': 0.0011649370968134988,\n",
       " 'bisous': 0.0011649370968134988,\n",
       " 'touche': 0.0011649370968134988,\n",
       " 'paie': 0.0011649370968134988,\n",
       " '12': 0.0011649370968134988,\n",
       " 'donc': 0.0011649370968134988,\n",
       " 'juste': 0.0011649370968134988,\n",
       " 'avant': 0.0011649370968134988,\n",
       " 'parfait': 0.0011649370968134988,\n",
       " 'myself': 0.0011649370968134988,\n",
       " 'monde': 0.0011649370968134988,\n",
       " 'salut': 0.0011649370968134988,\n",
       " 'tombe': 0.0011649370968134988,\n",
       " 'trucs': 0.0011649370968134988,\n",
       " 'malsains': 0.0011649370968134988,\n",
       " '@kobar94': 0.0011649370968134988,\n",
       " 'passe': 0.0011649370968134988,\n",
       " 'wsh': 0.0011649370968134988,\n",
       " '@jlaseada': 0.0011649370968134988,\n",
       " 'madre': 0.0011649370968134988,\n",
       " 'best': 0.0011649370968134988,\n",
       " 'troll': 0.0011649370968134988,\n",
       " 'player': 0.0011649370968134988,\n",
       " 'ever': 0.0011649370968134988,\n",
       " 'ptdddddddddddr': 0.0011649370968134988,\n",
       " '@shanaxo13': 0.0011649370968134988,\n",
       " 'fais': 0.0011649370968134988,\n",
       " 'compte': 0.0011649370968134988,\n",
       " 'ton': 0.0011649370968134988,\n",
       " 'ancien': 0.001959182857413081,\n",
       " '@': 0.0011649370968134988,\n",
       " 'qd': 0.0011649370968134988,\n",
       " 'voudras': 0.0011649370968134988,\n",
       " 'reprendre': 0.0011649370968134988,\n",
       " 'desac': 0.0011649370968134988,\n",
       " '@magic_jax': 0.0011649370968134988,\n",
       " 'lourd': 0.0011649370968134988,\n",
       " 'dingue': 0.0011649370968134988,\n",
       " 'plis': 0.0011649370968134988,\n",
       " 'contre': 0.0011649370968134988,\n",
       " 'connard': 0.0011649370968134988,\n",
       " 'sectaire': 0.0011649370968134988,\n",
       " 'merde': 0.0011649370968134988,\n",
       " '@clemplayers': 0.0011649370968134988,\n",
       " 'participation': 0.0011649370968134988,\n",
       " 'clem': 0.0011649370968134988,\n",
       " '@ungrosggatoi': 0.0011649370968134988,\n",
       " 'parles': 0.0011649370968134988,\n",
       " 'cynder': 0.0011649370968134988}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_neg_1 = {word: freqs[word]**(3/4) for word in freqs}\n",
    "total_neg = 0\n",
    "for word in p_neg_1:\n",
    "    total_neg+=p_neg_1[word]\n",
    "p_neg = {word: p_neg_1[word]/total_neg for word in p_neg_1}\n",
    "p_neg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Étape 3 : Créations pairs mots centraux / contexte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "mot_index = {w: index for (index, w) in enumerate(voc)}\n",
    "index_mot = {index: w for (index, w) in enumerate(voc)}\n",
    "\n",
    "taille_fenetre = 4\n",
    "index_pairs = []\n",
    "# On traite chaque phrase.\n",
    "for phrase in t_corpus:\n",
    "    indices = [mot_index[mot] for mot in phrase]\n",
    "    # On traite chaque mot comme un mot central\n",
    "    for center_word in range(len(indices)):\n",
    "        # Pour chaque fenetre possible\n",
    "        for w in range(-taille_fenetre, taille_fenetre + 1):\n",
    "            context_word = center_word + w\n",
    "            # On fait attention à ne pas sauter de phrases\n",
    "            if context_word < 0 or context_word >= len(indices) or center_word == context_word:\n",
    "                continue\n",
    "            context_word_ind = indices[context_word]\n",
    "            index_pairs.append((indices[center_word], context_word_ind))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  1],\n",
       "       [ 0,  2],\n",
       "       [ 0,  3],\n",
       "       [ 0,  4],\n",
       "       [ 1,  0],\n",
       "       [ 1,  2],\n",
       "       [ 1,  3],\n",
       "       [ 1,  4],\n",
       "       [ 1,  5],\n",
       "       [ 2,  0],\n",
       "       [ 2,  1],\n",
       "       [ 2,  3],\n",
       "       [ 2,  4],\n",
       "       [ 2,  5],\n",
       "       [ 2,  6],\n",
       "       [ 3,  0],\n",
       "       [ 3,  1],\n",
       "       [ 3,  2],\n",
       "       [ 3,  4],\n",
       "       [ 3,  5],\n",
       "       [ 3,  6],\n",
       "       [ 3,  7],\n",
       "       [ 4,  0],\n",
       "       [ 4,  1],\n",
       "       [ 4,  2],\n",
       "       [ 4,  3],\n",
       "       [ 4,  5],\n",
       "       [ 4,  6],\n",
       "       [ 4,  7],\n",
       "       [ 4,  8],\n",
       "       [ 5,  1],\n",
       "       [ 5,  2],\n",
       "       [ 5,  3],\n",
       "       [ 5,  4],\n",
       "       [ 5,  6],\n",
       "       [ 5,  7],\n",
       "       [ 5,  8],\n",
       "       [ 5,  9],\n",
       "       [ 6,  2],\n",
       "       [ 6,  3],\n",
       "       [ 6,  4],\n",
       "       [ 6,  5],\n",
       "       [ 6,  7],\n",
       "       [ 6,  8],\n",
       "       [ 6,  9],\n",
       "       [ 7,  3],\n",
       "       [ 7,  4],\n",
       "       [ 7,  5],\n",
       "       [ 7,  6],\n",
       "       [ 7,  8],\n",
       "       [ 7,  9],\n",
       "       [ 8,  4],\n",
       "       [ 8,  5],\n",
       "       [ 8,  6],\n",
       "       [ 8,  7],\n",
       "       [ 8,  9],\n",
       "       [ 9,  5],\n",
       "       [ 9,  6],\n",
       "       [ 9,  7],\n",
       "       [ 9,  8],\n",
       "       [10, 11],\n",
       "       [10, 12],\n",
       "       [10, 13],\n",
       "       [10, 14],\n",
       "       [11, 10],\n",
       "       [11, 12],\n",
       "       [11, 13],\n",
       "       [11, 14],\n",
       "       [11, 15],\n",
       "       [12, 10],\n",
       "       [12, 11],\n",
       "       [12, 13],\n",
       "       [12, 14],\n",
       "       [12, 15],\n",
       "       [12, 16],\n",
       "       [13, 10],\n",
       "       [13, 11],\n",
       "       [13, 12],\n",
       "       [13, 14],\n",
       "       [13, 15],\n",
       "       [13, 16],\n",
       "       [13, 17],\n",
       "       [14, 10],\n",
       "       [14, 11],\n",
       "       [14, 12],\n",
       "       [14, 13],\n",
       "       [14, 15],\n",
       "       [14, 16],\n",
       "       [14, 17],\n",
       "       [14, 18],\n",
       "       [15, 11],\n",
       "       [15, 12],\n",
       "       [15, 13],\n",
       "       [15, 14],\n",
       "       [15, 16],\n",
       "       [15, 17],\n",
       "       [15, 18],\n",
       "       [15, 19],\n",
       "       [16, 12],\n",
       "       [16, 13],\n",
       "       [16, 14],\n",
       "       [16, 15],\n",
       "       [16, 17],\n",
       "       [16, 18],\n",
       "       [16, 19],\n",
       "       [16, 20],\n",
       "       [17, 13],\n",
       "       [17, 14],\n",
       "       [17, 15],\n",
       "       [17, 16],\n",
       "       [17, 18],\n",
       "       [17, 19],\n",
       "       [17, 20],\n",
       "       [18, 14],\n",
       "       [18, 15],\n",
       "       [18, 16],\n",
       "       [18, 17],\n",
       "       [18, 19],\n",
       "       [18, 20],\n",
       "       [19, 15],\n",
       "       [19, 16],\n",
       "       [19, 17],\n",
       "       [19, 18],\n",
       "       [19, 20],\n",
       "       [20, 16],\n",
       "       [20, 17],\n",
       "       [20, 18],\n",
       "       [20, 19],\n",
       "       [ 0, 21],\n",
       "       [ 0, 22],\n",
       "       [ 0, 23],\n",
       "       [21,  0],\n",
       "       [21, 22],\n",
       "       [21, 23],\n",
       "       [22,  0],\n",
       "       [22, 21],\n",
       "       [22, 23],\n",
       "       [23,  0],\n",
       "       [23, 21],\n",
       "       [23, 22],\n",
       "       [24, 25],\n",
       "       [24,  5],\n",
       "       [24, 26],\n",
       "       [24, 27],\n",
       "       [25, 24],\n",
       "       [25,  5],\n",
       "       [25, 26],\n",
       "       [25, 27],\n",
       "       [25, 28],\n",
       "       [ 5, 24]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_pairs_np = np.array(index_pairs)\n",
    "index_pairs_np[0:150]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Étape 4 : Création du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (<ipython-input-19-e0c5168699ce>, line 35)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-19-e0c5168699ce>\"\u001b[1;36m, line \u001b[1;32m35\u001b[0m\n\u001b[1;33m    for word, context in index_pairs:\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "#Couche d'entrée\n",
    "def get_input_layer(word_idx):\n",
    "    x = torch.zeros(voc_size).float()\n",
    "    x[word_idx] = 1.0\n",
    "    return x\n",
    "\n",
    "# Choix de dimension\n",
    "embedding_dims = 10\n",
    "# Initialisation\n",
    "# Variable : comme Tensor mais avec les valeurs qui changent pendant le traitement\n",
    "W1 = Variable(torch.randn(embedding_dims, voc_size).float(), requires_grad=True)\n",
    "W2 = Variable(torch.randn(voc_size, embedding_dims).float(), requires_grad=True)\n",
    "num_epochs = 10 # \"époques\"\n",
    "learning_rate = 0.01\n",
    "taille_fenetre = 4\n",
    "\n",
    "\n",
    "# Différentes étapes\n",
    "for epo in range(num_epochs):\n",
    "    loss_val = 0\n",
    "# On traite chaque phrase.\n",
    "    for phrase in t_corpus:\n",
    "        # Sub-sampling : pour chaque phrase, on réalise le subsampling éventuel.\n",
    "        for mot in phrase:\n",
    "            indice_mot = mot_index[mot]\n",
    "            if np.random.random() < (p_sub[indice_mot]):\n",
    "                x = Variable(get_input_layer(word)).float()\n",
    "                y_true = Variable(torch.from_numpy(np.array([context])).long())\n",
    "                z1 = torch.matmul(W1, x)\n",
    "                z2 = torch.matmul(W2, z1)\n",
    "                \n",
    "                \n",
    "                \n",
    "                log_softmax = F.log_softmax(z2, dim=0)\n",
    "\n",
    "                # nll_loss(pred/target) - negative log likehood\n",
    "                loss = F.nll_loss(log_softmax.view(1,-1), y_true)\n",
    "                loss_val += loss.data\n",
    "\n",
    "                # Propagation - revoir Pytorch.optimization\n",
    "                loss.backward()\n",
    "                W1.data -= learning_rate * W1.grad.data\n",
    "                W2.data -= learning_rate * W2.grad.data\n",
    "\n",
    "                W1.grad.data.zero_()\n",
    "                W2.grad.data.zero_()\n",
    "\n",
    "    print(f'Loss at epo {epo}: {loss_val/len(index_pairs)}')\n",
    "\n",
    "\n",
    "                \n",
    "#### OLD\n",
    "\n",
    "    for word, context in index_pairs:\n",
    "        # Sub-sampling : garde-t-on le mot contexte sur lequel on est ? Cela dépend de la proba calculée précédemment\n",
    "        word_context = index_mot[context]\n",
    "        # On tire un nombre selon une loi uniforme, si on est inf à la proba, on continue\n",
    "        if np.random.random() < (p_sub[word_context]):\n",
    "            # Prévoir aussi le negative sampling, l'idée est d'aller prendre un mot qui n'est pas dans le contexte (ou, plutôt un\n",
    "            # mot au hasard dans le voc et la proba qu'il soit dans le contexte est faible !)\n",
    "            x = Variable(get_input_layer(word)).float()\n",
    "            y_true = Variable(torch.from_numpy(np.array([context])).long())\n",
    "            print(y_true)\n",
    "            # Matmul = produits matriciels de deux tensors\n",
    "            z1 = torch.matmul(W1, x)\n",
    "            z2 = torch.matmul(W2, z1)\n",
    "\n",
    "            # Calcul softmax\n",
    "            log_softmax = F.log_softmax(z2, dim=0)\n",
    "\n",
    "            # nll_loss(pred/target) - negative log likehood\n",
    "            loss = F.nll_loss(log_softmax.view(1,-1), y_true)\n",
    "            loss_val += loss.data\n",
    "\n",
    "            # Propagation - revoir Pytorch.optimization\n",
    "            loss.backward()\n",
    "            W1.data -= learning_rate * W1.grad.data\n",
    "            W2.data -= learning_rate * W2.grad.data\n",
    "\n",
    "            W1.grad.data.zero_()\n",
    "            W2.grad.data.zero_()\n",
    "            \n",
    "    print(f'Loss at epo {epo}: {loss_val/len(index_pairs)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_input_layer(word_idx):\n",
    "    x = torch.zeros(voc_size).float()\n",
    "    x[word_idx] = 1.0\n",
    "    return x   \n",
    "x = Variable(get_input_layer(1)).float()\n",
    "x    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'W2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-b41dcd0dcb57>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mW2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mW2\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'W2' is not defined"
     ]
    }
   ],
   "source": [
    "W2[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distance/similarité cosinus\n",
    "def cos_distance(u, v):\n",
    "    return (np.dot(u, v)  / (math.sqrt(np.dot(u, u)) *  (math.sqrt(np.dot(v, v)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionnaire des poids\n",
    "mot_poids = {index_mot[index]: poids.detach().numpy() for (index, poids) in enumerate(W2)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Étape 5 : Résultats du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mot_plus_proche(word, n=5):\n",
    "    word_distance = {}\n",
    "    for mot in mot_poids:\n",
    "        if mot != word:\n",
    "            word_distance[mot] = (cos_distance(mot_poids[mot],(mot_poids[word])))\n",
    "    word_distance = sorted(word_distance.items(), key=lambda t: t[1],reverse=True)\n",
    "    return word_distance[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('rathalos', 0.7310312707276541),\n",
       " ('y', 0.7117773667606464),\n",
       " ('mtue', 0.6972553839008429),\n",
       " ('réveille', 0.6645014134124577),\n",
       " ('madre', 0.6638478961311802),\n",
       " ('😭', 0.6551260058122947),\n",
       " ('dodo', 0.6544916175622695),\n",
       " ('pense', 0.6393783723895966),\n",
       " ('glisse', 0.6249456152564727),\n",
       " ('✅', 0.6135785278345168)]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mot_poids\n",
    "mot_plus_proche(\"mort\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
