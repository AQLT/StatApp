{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import string\n",
    "import re\n",
    "import math\n",
    "import statistics\n",
    "from math import sqrt\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "import pandas as pd\n",
    "import nltk, re, pprint\n",
    "#nltk.download('punkt')\n",
    "from nltk import word_tokenize\n",
    "random.seed(1)\n",
    "np.random.seed(1)\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "from matplotlib import pyplot as plt\n",
    "import collections\n",
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.autograd as autograd\n",
    "\n",
    "import pickle\n",
    "\n",
    "os.chdir('C:/Users/torna/Documents/StatApp/StatApp')\n",
    "#os.chdir('/Users/alainquartierlatente/Desktop/Ensae/StatApp')\n",
    "#os.chdir('/home/aqlt/Documents/Ensae/StatApp')\n",
    "#os.chdir('C:/Users/Kim Antunez/Documents/Projets_autres/StatApp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sur 100K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99718\n"
     ]
    }
   ],
   "source": [
    "nom_dossier = \"100k\"\n",
    "# Penser à changer selon taille\n",
    "with open(\"data/corpus_trie%s.file\" %nom_dossier, \"rb\") as f:\n",
    "    corpus = pickle.load(f) \n",
    "ens_tweets = [phrase.split() for phrase in corpus]\n",
    "phrases = ens_tweets\n",
    "print(len(phrases))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['il',\n",
       "  'mérite',\n",
       "  'd',\n",
       "  'être',\n",
       "  'bloquer',\n",
       "  'la',\n",
       "  'lettre',\n",
       "  'de',\n",
       "  'l',\n",
       "  'alphabet'],\n",
       " ['nickname',\n",
       "  'et',\n",
       "  'fière',\n",
       "  'je',\n",
       "  't',\n",
       "  'en',\n",
       "  'voi',\n",
       "  'att',\n",
       "  'j',\n",
       "  'avais',\n",
       "  'oublié'],\n",
       " ['il', 'est', '1', 'heure']]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phrases[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-63-50a17aa01adc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mgensim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mword2vec\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m model = word2vec.Word2Vec(phrases, size=20, window=3,negative=5,alpha=0.01,seed=1,\n\u001b[1;32m----> 3\u001b[1;33m                           min_count=5, workers=4, iter=10)\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;31m# phrases = les phrases du corpus\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# size = dimension du vecteur\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\gensim\\models\\word2vec.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, sentences, corpus_file, size, alpha, window, min_count, max_vocab_size, sample, seed, workers, min_alpha, sg, hs, negative, ns_exponent, cbow_mean, hashfxn, iter, null_word, trim_rule, sorted_vocab, batch_words, compute_loss, callbacks, max_final_vocab)\u001b[0m\n\u001b[0;32m    781\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_words\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_words\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrim_rule\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrim_rule\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msg\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwindow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mwindow\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m             \u001b[0mseed\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mhs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnegative\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnegative\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcbow_mean\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcbow_mean\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_alpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmin_alpha\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompute_loss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcompute_loss\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 783\u001b[1;33m             fast_version=FAST_VERSION)\n\u001b[0m\u001b[0;32m    784\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    785\u001b[0m     def _do_train_epoch(self, corpus_file, thread_id, offset, cython_vocab, thread_private_mem, cur_epoch,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\gensim\\models\\base_any2vec.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, sentences, corpus_file, workers, vector_size, epochs, callbacks, batch_words, trim_rule, sg, alpha, window, seed, hs, negative, ns_exponent, cbow_mean, min_alpha, compute_loss, fast_version, **kwargs)\u001b[0m\n\u001b[0;32m    757\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"You can't pass a generator as the sentences argument. Try a sequence.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    758\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 759\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild_vocab\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msentences\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcorpus_file\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcorpus_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrim_rule\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrim_rule\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    760\u001b[0m             self.train(\n\u001b[0;32m    761\u001b[0m                 \u001b[0msentences\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msentences\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcorpus_file\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcorpus_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtotal_examples\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcorpus_count\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\gensim\\models\\base_any2vec.py\u001b[0m in \u001b[0;36mbuild_vocab\u001b[1;34m(self, sentences, corpus_file, update, progress_per, keep_raw_vocab, trim_rule, **kwargs)\u001b[0m\n\u001b[0;32m    934\u001b[0m         \"\"\"\n\u001b[0;32m    935\u001b[0m         total_words, corpus_count = self.vocabulary.scan_vocab(\n\u001b[1;32m--> 936\u001b[1;33m             sentences=sentences, corpus_file=corpus_file, progress_per=progress_per, trim_rule=trim_rule)\n\u001b[0m\u001b[0;32m    937\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcorpus_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcorpus_count\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    938\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcorpus_total_words\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtotal_words\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\gensim\\models\\word2vec.py\u001b[0m in \u001b[0;36mscan_vocab\u001b[1;34m(self, sentences, corpus_file, progress_per, workers, trim_rule)\u001b[0m\n\u001b[0;32m   1590\u001b[0m             \u001b[0msentences\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLineSentence\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcorpus_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1591\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1592\u001b[1;33m         \u001b[0mtotal_words\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcorpus_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_scan_vocab\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprogress_per\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrim_rule\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1593\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1594\u001b[0m         logger.info(\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\gensim\\models\\word2vec.py\u001b[0m in \u001b[0;36m_scan_vocab\u001b[1;34m(self, sentences, progress_per, trim_rule)\u001b[0m\n\u001b[0;32m   1574\u001b[0m                 )\n\u001b[0;32m   1575\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msentence\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1576\u001b[1;33m                 \u001b[0mvocab\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1577\u001b[0m             \u001b[0mtotal_words\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1578\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from gensim.models import word2vec\n",
    "model = word2vec.Word2Vec(phrases, size=20, window=3,negative=5,alpha=0.01,seed=1,\n",
    "                          min_count=5, workers=4, iter=10)\n",
    "# phrases = les phrases du corpus\n",
    "# size = dimension du vecteur\n",
    "# window = fenetre\n",
    "# negative = nb de neg samples\n",
    "# alpha = learning rate\n",
    "# seed \n",
    "# min_count = fréquence min des mots qui nous intéresse\n",
    "# workers = nb de cores sur l'ordi\n",
    "# iter = nb epoch\n",
    "model.corpus_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['il', 'mérite', 'd', 'être', 'bloquer']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = model.wv.vocab\n",
    "list(vocab)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.0212375 ,  0.43549496,  2.3465245 , -1.2005298 ,  1.1559012 ,\n",
       "        0.057466  , -0.10714477,  0.6737687 , -0.7785982 , -0.24978723,\n",
       "        2.3176663 ,  0.23717044, -1.169239  , -0.21243164, -0.8299047 ,\n",
       "        1.730058  ,  0.9359951 , -2.3995419 ,  1.5362434 , -0.19903699],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv['wesh']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\torna\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `similarity` (Method will be removed in 4.0.0, use self.wv.similarity() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.582294"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.similarity(\"homme\",\"femme\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cos_distance(u, v):\n",
    "    return (np.dot(u, v)  / (math.sqrt(np.dot(u, u)) *  (math.sqrt(np.dot(v, v)))))\n",
    "\n",
    "def eucl_distance(u, v):\n",
    "    return (np.linalg.norm(u-v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance_mots(word1,word2):\n",
    "    if word1 in vocab and word2 in vocab:\n",
    "        word_distance = model.similarity(word1,word2)\n",
    "    else:\n",
    "         word_distance = float('nan')\n",
    "    return word_distance\n",
    "distance_mots_v = np.vectorize(distance_mots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\torna\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: DeprecationWarning: Call to deprecated `similarity` (Method will be removed in 4.0.0, use self.wv.similarity() instead).\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.582294"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distance_mots(\"homme\",\"femme\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word1</th>\n",
       "      <th>word2</th>\n",
       "      <th>corr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>corde</td>\n",
       "      <td>sourire</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>midi</td>\n",
       "      <td>ficelle</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>coq</td>\n",
       "      <td>périple</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fruit</td>\n",
       "      <td>fournaise</td>\n",
       "      <td>0.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>autographe</td>\n",
       "      <td>rivage</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>coussin</td>\n",
       "      <td>oreiller</td>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>cimetière</td>\n",
       "      <td>cimetière</td>\n",
       "      <td>4.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>automobile</td>\n",
       "      <td>auto</td>\n",
       "      <td>3.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>joyau</td>\n",
       "      <td>bijou</td>\n",
       "      <td>3.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>midi</td>\n",
       "      <td>dîner</td>\n",
       "      <td>2.17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>65 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         word1      word2  corr\n",
       "0        corde    sourire  0.00\n",
       "1         midi    ficelle  0.00\n",
       "2          coq    périple  0.06\n",
       "3        fruit  fournaise  0.11\n",
       "4   autographe     rivage  0.00\n",
       "..         ...        ...   ...\n",
       "60     coussin   oreiller  3.00\n",
       "61   cimetière  cimetière  4.00\n",
       "62  automobile       auto  3.94\n",
       "63       joyau      bijou  3.22\n",
       "64        midi      dîner  2.17\n",
       "\n",
       "[65 rows x 3 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_base = pd.read_csv('data_bis/word_similarity.csv', sep=\";\")\n",
    "df_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65\n",
      "13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\torna\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: DeprecationWarning: Call to deprecated `similarity` (Method will be removed in 4.0.0, use self.wv.similarity() instead).\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word1</th>\n",
       "      <th>word2</th>\n",
       "      <th>corr</th>\n",
       "      <th>corr_word2vec_cos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>corde</td>\n",
       "      <td>sourire</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.206890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>côte</td>\n",
       "      <td>forêt</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.726424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>garçon</td>\n",
       "      <td>sage</td>\n",
       "      <td>0.29</td>\n",
       "      <td>-0.000511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>gars</td>\n",
       "      <td>sorcier</td>\n",
       "      <td>0.44</td>\n",
       "      <td>-0.013237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>oiseau</td>\n",
       "      <td>bois</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.343423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>auto</td>\n",
       "      <td>voyage</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.017356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>verre</td>\n",
       "      <td>bijou</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.499181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>frère</td>\n",
       "      <td>gars</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.683955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>sage</td>\n",
       "      <td>sorcier</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.239894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>nourriture</td>\n",
       "      <td>fruit</td>\n",
       "      <td>2.78</td>\n",
       "      <td>0.659608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>forêt</td>\n",
       "      <td>bois</td>\n",
       "      <td>3.72</td>\n",
       "      <td>0.407164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>garçon</td>\n",
       "      <td>gars</td>\n",
       "      <td>3.83</td>\n",
       "      <td>0.429132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>midi</td>\n",
       "      <td>dîner</td>\n",
       "      <td>2.17</td>\n",
       "      <td>0.223129</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         word1    word2  corr  corr_word2vec_cos\n",
       "0        corde  sourire  0.00           0.206890\n",
       "16        côte    forêt  0.22           0.726424\n",
       "20      garçon     sage  0.29          -0.000511\n",
       "23        gars  sorcier  0.44          -0.013237\n",
       "28      oiseau     bois  0.06           0.343423\n",
       "33        auto   voyage  0.33           0.017356\n",
       "35       verre    bijou  0.56           0.499181\n",
       "38       frère     gars  2.00           0.683955\n",
       "39        sage  sorcier  0.83           0.239894\n",
       "43  nourriture    fruit  2.78           0.659608\n",
       "56       forêt     bois  3.72           0.407164\n",
       "59      garçon     gars  3.83           0.429132\n",
       "64        midi    dîner  2.17           0.223129"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distance_mots_v = np.vectorize(distance_mots)\n",
    "df = df_base\n",
    "df[\"corr_word2vec_cos\"] = distance_mots_v(df[\"word1\"],df[\"word2\"])\n",
    "print(len(df))\n",
    "df = df.dropna()\n",
    "print(len(df))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le résultat de word2vec COSINUS est différent de celui du human judgement (non rejet de H0 = non corrélation) p=0.280 / Valeur de la corrélation : 0.324\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import spearmanr\n",
    "#On fait des tests à 5 % pour la distance cosinus\n",
    "alpha = 0.05\n",
    "corr, p_value = spearmanr(df[\"corr\"], df[\"corr_word2vec_cos\"])\n",
    "if p_value > alpha:\n",
    "    print('Le résultat de word2vec COSINUS est différent de celui du human judgement (non rejet de H0 = non corrélation) p=%.3f' % p_value,'/ Valeur de la corrélation : %.3f'% corr)\n",
    "else:\n",
    "    print('Le résultat de word2vec COSINUS est semblable celui du human judgement (rejet de H0 = non corrélation) p=%.3f' % p_value,'/ Valeur de la corrélation : %.3f'% corr)\n",
    "\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sur l'ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1348627\n"
     ]
    }
   ],
   "source": [
    "nom_dossier = \"ens\"\n",
    "# Penser à changer selon taille\n",
    "with open(\"data/corpus_trie%s.file\" %nom_dossier, \"rb\") as f:\n",
    "    corpus = pickle.load(f) \n",
    "ens_tweets = [phrase.split() for phrase in corpus]\n",
    "phrases = ens_tweets\n",
    "print(len(phrases))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1348627"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = word2vec.Word2Vec(phrases, size=100, window=3,negative=5,alpha=0.01,seed=1,\n",
    "                          min_count=5, workers=4, iter=100)\n",
    "# phrases = les phrases du corpus\n",
    "# size = dimension du vecteur\n",
    "# window = fenetre\n",
    "# negative = nb de neg samples\n",
    "# alpha = learning rate\n",
    "# seed \n",
    "# min_count = fréquence min des mots qui nous intéresse\n",
    "# workers = nb de cores sur l'ordi\n",
    "# iter = nb epoch\n",
    "model.corpus_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['il', 'mérite', 'd', 'être', 'bloquer']"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = model.wv.vocab\n",
    "list(vocab)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65\n",
      "52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\torna\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: DeprecationWarning: Call to deprecated `similarity` (Method will be removed in 4.0.0, use self.wv.similarity() instead).\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word1</th>\n",
       "      <th>word2</th>\n",
       "      <th>corr</th>\n",
       "      <th>corr_word2vec_cos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>corde</td>\n",
       "      <td>sourire</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.142178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>midi</td>\n",
       "      <td>ficelle</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.031496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>coq</td>\n",
       "      <td>périple</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.286557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>automobile</td>\n",
       "      <td>sorcier</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.041289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>grimace</td>\n",
       "      <td>instrument</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.116685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>refuge</td>\n",
       "      <td>fruit</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.372516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>refuge</td>\n",
       "      <td>moine</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.333038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>cimetière</td>\n",
       "      <td>asylum</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.134455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>garçon</td>\n",
       "      <td>coq</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.444427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>verre</td>\n",
       "      <td>magicien</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.259648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>coussin</td>\n",
       "      <td>bijou</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.450154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>moine</td>\n",
       "      <td>esclave</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.286297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>refuge</td>\n",
       "      <td>cimetière</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.450979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>côte</td>\n",
       "      <td>forêt</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.412417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>grimace</td>\n",
       "      <td>gars</td>\n",
       "      <td>0.11</td>\n",
       "      <td>-0.121665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>moine</td>\n",
       "      <td>oracle</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.075757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>garçon</td>\n",
       "      <td>sage</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.220937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>automobile</td>\n",
       "      <td>coussin</td>\n",
       "      <td>0.06</td>\n",
       "      <td>-0.011842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>gars</td>\n",
       "      <td>sorcier</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.401223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>forêt</td>\n",
       "      <td>cimetière</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.259707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>nourriture</td>\n",
       "      <td>coq</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.128284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>cimetière</td>\n",
       "      <td>bois</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.112380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>oiseau</td>\n",
       "      <td>bois</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.130531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>côte</td>\n",
       "      <td>colline</td>\n",
       "      <td>2.17</td>\n",
       "      <td>0.475951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>grue</td>\n",
       "      <td>coq</td>\n",
       "      <td>0.28</td>\n",
       "      <td>-0.001749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>colline</td>\n",
       "      <td>bois</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.054744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>auto</td>\n",
       "      <td>voyage</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.019036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>verre</td>\n",
       "      <td>bijou</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.368537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>magicien</td>\n",
       "      <td>oracle</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.184551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>grue</td>\n",
       "      <td>instrument</td>\n",
       "      <td>0.94</td>\n",
       "      <td>-0.188681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>frère</td>\n",
       "      <td>gars</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.618161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>sage</td>\n",
       "      <td>sorcier</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.282739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>oracle</td>\n",
       "      <td>sage</td>\n",
       "      <td>1.28</td>\n",
       "      <td>0.179646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>oiseau</td>\n",
       "      <td>grue</td>\n",
       "      <td>1.65</td>\n",
       "      <td>-0.026912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>oiseau</td>\n",
       "      <td>coq</td>\n",
       "      <td>2.41</td>\n",
       "      <td>0.480615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>nourriture</td>\n",
       "      <td>fruit</td>\n",
       "      <td>2.78</td>\n",
       "      <td>0.301214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>frère</td>\n",
       "      <td>moine</td>\n",
       "      <td>2.89</td>\n",
       "      <td>0.147851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>refuge</td>\n",
       "      <td>asile</td>\n",
       "      <td>3.28</td>\n",
       "      <td>0.154871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>magicien</td>\n",
       "      <td>sorcier</td>\n",
       "      <td>2.67</td>\n",
       "      <td>0.443328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>corde</td>\n",
       "      <td>ficelle</td>\n",
       "      <td>3.33</td>\n",
       "      <td>0.369041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>grimace</td>\n",
       "      <td>sourire</td>\n",
       "      <td>1.50</td>\n",
       "      <td>0.218192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>voyage</td>\n",
       "      <td>périple</td>\n",
       "      <td>2.59</td>\n",
       "      <td>0.553120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>autographe</td>\n",
       "      <td>signature</td>\n",
       "      <td>3.56</td>\n",
       "      <td>0.098177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>forêt</td>\n",
       "      <td>bois</td>\n",
       "      <td>3.72</td>\n",
       "      <td>0.212360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>instrument</td>\n",
       "      <td>outil</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.604573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>coq</td>\n",
       "      <td>coq</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>garçon</td>\n",
       "      <td>gars</td>\n",
       "      <td>3.83</td>\n",
       "      <td>0.476363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>coussin</td>\n",
       "      <td>oreiller</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.726056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>cimetière</td>\n",
       "      <td>cimetière</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>automobile</td>\n",
       "      <td>auto</td>\n",
       "      <td>3.94</td>\n",
       "      <td>0.304626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>joyau</td>\n",
       "      <td>bijou</td>\n",
       "      <td>3.22</td>\n",
       "      <td>0.426861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>midi</td>\n",
       "      <td>dîner</td>\n",
       "      <td>2.17</td>\n",
       "      <td>0.442962</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         word1       word2  corr  corr_word2vec_cos\n",
       "0        corde     sourire  0.00           0.142178\n",
       "1         midi     ficelle  0.00          -0.031496\n",
       "2          coq     périple  0.06           0.286557\n",
       "5   automobile     sorcier  0.00           0.041289\n",
       "7      grimace  instrument  0.00           0.116685\n",
       "8       refuge       fruit  0.00           0.372516\n",
       "9       refuge       moine  0.22           0.333038\n",
       "10   cimetière      asylum  0.22           0.134455\n",
       "11      garçon         coq  0.44           0.444427\n",
       "12       verre    magicien  0.06           0.259648\n",
       "13     coussin       bijou  0.17           0.450154\n",
       "14       moine     esclave  0.17           0.286297\n",
       "15      refuge   cimetière  0.50           0.450979\n",
       "16        côte       forêt  0.22           0.412417\n",
       "17     grimace        gars  0.11          -0.121665\n",
       "19       moine      oracle  0.39           0.075757\n",
       "20      garçon        sage  0.29           0.220937\n",
       "21  automobile     coussin  0.06          -0.011842\n",
       "23        gars     sorcier  0.44           0.401223\n",
       "24       forêt   cimetière  0.17           0.259707\n",
       "25  nourriture         coq  0.61           0.128284\n",
       "26   cimetière        bois  0.11           0.112380\n",
       "28      oiseau        bois  0.06           0.130531\n",
       "29        côte     colline  2.17           0.475951\n",
       "31        grue         coq  0.28          -0.001749\n",
       "32     colline        bois  0.44           0.054744\n",
       "33        auto      voyage  0.33           0.019036\n",
       "35       verre       bijou  0.56           0.368537\n",
       "36    magicien      oracle  0.56           0.184551\n",
       "37        grue  instrument  0.94          -0.188681\n",
       "38       frère        gars  2.00           0.618161\n",
       "39        sage     sorcier  0.83           0.282739\n",
       "40      oracle        sage  1.28           0.179646\n",
       "41      oiseau        grue  1.65          -0.026912\n",
       "42      oiseau         coq  2.41           0.480615\n",
       "43  nourriture       fruit  2.78           0.301214\n",
       "44       frère       moine  2.89           0.147851\n",
       "45      refuge       asile  3.28           0.154871\n",
       "47    magicien     sorcier  2.67           0.443328\n",
       "49       corde     ficelle  3.33           0.369041\n",
       "51     grimace     sourire  1.50           0.218192\n",
       "53      voyage     périple  2.59           0.553120\n",
       "54  autographe   signature  3.56           0.098177\n",
       "56       forêt        bois  3.72           0.212360\n",
       "57  instrument       outil  3.00           0.604573\n",
       "58         coq         coq  4.00           1.000000\n",
       "59      garçon        gars  3.83           0.476363\n",
       "60     coussin    oreiller  3.00           0.726056\n",
       "61   cimetière   cimetière  4.00           1.000000\n",
       "62  automobile        auto  3.94           0.304626\n",
       "63       joyau       bijou  3.22           0.426861\n",
       "64        midi       dîner  2.17           0.442962"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_base = pd.read_csv('data_bis/word_similarity.csv', sep=\";\")\n",
    "distance_mots_v = np.vectorize(distance_mots)\n",
    "df = df_base\n",
    "df[\"corr_word2vec_cos\"] = distance_mots_v(df[\"word1\"],df[\"word2\"])\n",
    "print(len(df))\n",
    "df = df.dropna()\n",
    "print(len(df))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le résultat de word2vec COSINUS est semblable celui du human judgement (rejet de H0 = non corrélation) p=0.000 / Valeur de la corrélation : 0.479\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import spearmanr\n",
    "#On fait des tests à 5 % pour la distance cosinus\n",
    "alpha = 0.05\n",
    "corr, p_value = spearmanr(df[\"corr\"], df[\"corr_word2vec_cos\"])\n",
    "if p_value > alpha:\n",
    "    print('Le résultat de word2vec COSINUS est différent de celui du human judgement (non rejet de H0 (= non corrélation) p=%.3f' % p_value,'/ Valeur de la corrélation : %.3f'% corr)\n",
    "else:\n",
    "    print('Le résultat de word2vec COSINUS est semblable celui du human judgement (rejet de H0 (= non corrélation)) p=%.3f' % p_value,'/ Valeur de la corrélation : %.3f'% corr)\n",
    "\n",
    "print(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
