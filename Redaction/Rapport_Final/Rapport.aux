\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\zref@newlabel[2]{}
\bbl@cs{beforestart}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\babel@aux{french}{}
\citation{Mikolov}
\citation{Mikolov}
\citation{Jurafsky}
\newlabel{introduction}{{}{2}{Introduction}{section*.2}{}}
\@writefile{toc}{\contentsline {section}{Introduction}{2}{section*.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {1}Implémentation du modèle \emph  {Word2Vec}}{2}{section.1}\protected@file@percent }
\newlabel{sec:word2vec}{{1}{2}{\texorpdfstring {Implémentation du modèle \emph {Word2Vec}}{Implémentation du modèle Word2Vec}}{section.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1}Le modèle \emph  {Word2vec}, un modèle de \emph  {word-embedding}}{2}{subsection.1.1}\protected@file@percent }
\newlabel{le-moduxe8le-word2vec-un-moduxe8le-de-word-embedding}{{1.1}{2}{\texorpdfstring {Le modèle \emph {Word2vec}, un modèle de \emph {word-embedding}}{Le modèle Word2vec, un modèle de word-embedding}}{subsection.1.1}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.1.1}Historique : de la sémantique vectorielle à \emph  {Word2Vec}}{2}{subsubsection.1.1.1}\protected@file@percent }
\newlabel{historique-de-la-suxe9mantique-vectorielle-uxe0-word2vec}{{1.1.1}{2}{\texorpdfstring {Historique : de la sémantique vectorielle à \emph {Word2Vec}}{Historique : de la sémantique vectorielle à Word2Vec}}{subsubsection.1.1.1}{}}
\citation{Mikolov}
\citation{Bengio}
\citation{Mikolov}
\citation{Mikolov}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.1.2}\emph  {Word2Vec}, un modèle d'apprentissage «\nobreakspace  {}auto-supervisé\nobreakspace  {}»}{3}{subsubsection.1.1.2}\protected@file@percent }
\newlabel{subsec:word2vec}{{1.1.2}{3}{\texorpdfstring {\emph {Word2Vec}, un modèle d'apprentissage «~auto-supervisé~»}{Word2Vec, un modèle d'apprentissage «~auto-supervisé~»}}{subsubsection.1.1.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Architecture des modèles Continuous bags of words (CBOW) et Skip-gram.\relax }}{3}{figure.caption.3}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:cbowskipgram}{{1}{3}{Architecture des modèles Continuous bags of words (CBOW) et Skip-gram.\relax }{figure.caption.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2}L'algorithme Skip-Gram}{4}{subsection.1.2}\protected@file@percent }
\newlabel{sec:skipgram}{{1.2}{4}{L'algorithme Skip-Gram}{subsection.1.2}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.2.1}Construction de la base d'entraînement}{4}{subsubsection.1.2.1}\protected@file@percent }
\newlabel{subsec:baseentrainement}{{1.2.1}{4}{Construction de la base d'entraînement}{subsubsection.1.2.1}{}}
\citation{Mikolov}
\citation{MikolovNS}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.2.2}Descente de gradient}{6}{subsubsection.1.2.2}\protected@file@percent }
\newlabel{subsec:descentedegradient}{{1.2.2}{6}{Descente de gradient}{subsubsection.1.2.2}{}}
\newlabel{subsec:softmax}{{1.2.2.1}{6}{Version softmax}{paragraph.1.2.2.1}{}}
\@writefile{toc}{\contentsline {paragraph}{\numberline {1.2.2.1}Version softmax}{6}{paragraph.1.2.2.1}\protected@file@percent }
\newlabel{eq:objSoftMax}{{1}{6}{Version softmax}{equation.1.1}{}}
\citation{MikolovNS}
\newlabel{subsec:negsampling}{{1.2.2.2}{7}{\texorpdfstring {Version \emph {negative sampling}}{Version negative sampling}}{paragraph.1.2.2.2}{}}
\@writefile{toc}{\contentsline {paragraph}{\numberline {1.2.2.2}Version \emph  {negative sampling}}{7}{paragraph.1.2.2.2}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Mots les plus proches de \FB@og  grand \FB@fg  \relax {} par similarité cosinus\relax }}{8}{table.caption.4}\protected@file@percent }
\newlabel{table:tableau_evaluation}{{1}{8}{Mots les plus proches de \og grand \fg {} par similarité cosinus\relax }{table.caption.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Évaluation du modèle implémenté}{8}{section.2}\protected@file@percent }
\newlabel{sec:evaluation}{{2}{8}{Évaluation du modèle implémenté}{section.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Évaluation sur un corpus fictif}{8}{subsection.2.1}\protected@file@percent }
\newlabel{sec:corpusFictif}{{2.1}{8}{Évaluation sur un corpus fictif}{subsection.2.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Choix des meilleurs hyperparamètres pour le modèle}{8}{subsection.2.2}\protected@file@percent }
\newlabel{sec:hyperparametres}{{2.2}{8}{Choix des meilleurs hyperparamètres pour le modèle}{subsection.2.2}{}}
\citation{Hutter}
\citation{Rehurek}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Évaluation du modèle sur données fictives\relax }}{9}{figure.caption.5}\protected@file@percent }
\newlabel{fig:figure_evaluation}{{2}{9}{Évaluation du modèle sur données fictives\relax }{figure.caption.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Tests d'hyperparamètres : epochs, fenêtre et taux d'apprentissage\relax }}{10}{figure.caption.6}\protected@file@percent }
\newlabel{fig:evaluation_1}{{3}{10}{Tests d'hyperparamètres : epochs, fenêtre et taux d'apprentissage\relax }{figure.caption.6}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.1}Nombre d'epochs, taille de fenêtre et taux d'apprentissage}{10}{subsubsection.2.2.1}\protected@file@percent }
\newlabel{nombre-depochs-taille-de-fenuxeatre-et-taux-dapprentissage}{{2.2.1}{10}{Nombre d'epochs, taille de fenêtre et taux d'apprentissage}{subsubsection.2.2.1}{}}
\newlabel{le-nombre-depochs}{{2.2.1.1}{10}{Le nombre d'epochs}{paragraph.2.2.1.1}{}}
\@writefile{toc}{\contentsline {paragraph}{\numberline {2.2.1.1}Le nombre d'epochs}{10}{paragraph.2.2.1.1}\protected@file@percent }
\citation{Levy2}
\citation{Pennington}
\citation{Mikolov}
\newlabel{le-taux-dapprentissage}{{2.2.1.2}{11}{Le taux d'apprentissage}{paragraph.2.2.1.2}{}}
\@writefile{toc}{\contentsline {paragraph}{\numberline {2.2.1.2}Le taux d'apprentissage}{11}{paragraph.2.2.1.2}\protected@file@percent }
\newlabel{la-taille-de-la-fenuxeatre}{{2.2.1.3}{11}{La taille de la fenêtre}{paragraph.2.2.1.3}{}}
\@writefile{toc}{\contentsline {paragraph}{\numberline {2.2.1.3}La taille de la fenêtre}{11}{paragraph.2.2.1.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.2}Dimension des vecteurs-mots}{11}{subsubsection.2.2.2}\protected@file@percent }
\newlabel{dimension-des-vecteurs-mots}{{2.2.2}{11}{Dimension des vecteurs-mots}{subsubsection.2.2.2}{}}
\citation{Mikolov}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Tests d'hyperparamètres : dimension des *word-embeddings*\relax }}{12}{figure.caption.7}\protected@file@percent }
\newlabel{fig:figure_dim}{{4}{12}{Tests d'hyperparamètres : dimension des *word-embeddings*\relax }{figure.caption.7}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Évaluation sur le corpus final}{12}{subsection.2.3}\protected@file@percent }
\newlabel{uxe9valuation-sur-le-corpus-final}{{2.3}{12}{Évaluation sur le corpus final}{subsection.2.3}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.3.1}Avec \FB@og  notre \FB@fg  \relax {} modèle}{12}{subsubsection.2.3.1}\protected@file@percent }
\newlabel{avec-notre-moduxe8le}{{2.3.1}{12}{\texorpdfstring {Avec \og notre \fg {} modèle}{Avec notre modèle}}{subsubsection.2.3.1}{}}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces 10 plus proches voisins par similarité cosinus avec \FB@og  notre \FB@fg  \relax {} modèle\relax }}{13}{table.caption.8}\protected@file@percent }
\newlabel{table:knn_ark}{{2}{13}{10 plus proches voisins par similarité cosinus avec \og notre \fg {} modèle\relax }{table.caption.8}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Position des mots en fonction de\newline  leur nombre d'occurrences (Modèle \texttt  {Gensim})\relax }}{13}{figure.caption.9}\protected@file@percent }
\newlabel{fig:acp_freq_gensim}{{5}{13}{Position des mots en fonction de\newline leur nombre d'occurrences (Modèle \texttt {Gensim})\relax }{figure.caption.9}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Position des mots en fonction de\newline  leur nombre d'occurrences (\FB@og  notre \FB@fg  \relax {} modèle)\relax }}{13}{figure.caption.9}\protected@file@percent }
\newlabel{fig:acp_freq_ark}{{6}{13}{Position des mots en fonction de\newline leur nombre d'occurrences (\og notre \fg {} modèle)\relax }{figure.caption.9}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.3.2}Avec le modèle \texttt  {Gensim}}{13}{subsubsection.2.3.2}\protected@file@percent }
\newlabel{sec:gensimresultats}{{2.3.2}{13}{\texorpdfstring {Avec le modèle \texttt {Gensim}}{Avec le modèle Gensim}}{subsubsection.2.3.2}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces 10 plus proches voisins par similarité cosinus avec le modèle \texttt  {Gensim}\relax }}{14}{table.caption.10}\protected@file@percent }
\newlabel{table:knn_gensim}{{3}{14}{10 plus proches voisins par similarité cosinus avec le modèle \texttt {Gensim}\relax }{table.caption.10}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces ACP sur un corpus réduit de mots\relax }}{14}{figure.caption.11}\protected@file@percent }
\newlabel{fig:acp_gensim}{{7}{14}{ACP sur un corpus réduit de mots\relax }{figure.caption.11}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces \ $\overrightarrow {Roi} - \overrightarrow {Homme} + \overrightarrow {Femme} = $ ?\relax }}{15}{figure.caption.12}\protected@file@percent }
\newlabel{fig:acp_reine}{{8}{15}{\ $\protect \overrightarrow {Roi} - \protect \overrightarrow {Homme} + \protect \overrightarrow {Femme} = $ ?\relax }{figure.caption.12}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces \ $\overrightarrow {Paris} - \overrightarrow {France} + \overrightarrow {Italie} = $ ?\relax }}{15}{figure.caption.12}\protected@file@percent }
\newlabel{fig:acp_rome}{{9}{15}{\ $\protect \overrightarrow {Paris} - \protect \overrightarrow {France} + \protect \overrightarrow {Italie} = $ ?\relax }{figure.caption.12}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Construction d'un indice mensuel de sentiments moyens des tweets}{15}{section.3}\protected@file@percent }
\newlabel{sec:sentimentalAnalysis}{{3}{15}{Construction d'un indice mensuel de sentiments moyens des tweets}{section.3}{}}
\newlabel{enc:encadre1}{{1}{15}{Construction d'un indice mensuel de sentiments moyens des tweets}{bclogocompteur.1}{}}
\@writefile{bcl}{\contentsline {bclogo}{ {\sc  \textbf  {Encadré 1}} - Données utilisées}{15}{bclogocompteur.1}\protected@file@percent }
\pgfsyspdfmark {pgfid1}{4499457}{4499457}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces Optimisation du seuil $\gamma $ pour le modèle à partir des sentiments moyens des mots\relax }}{16}{figure.caption.13}\protected@file@percent }
\newlabel{fig:max_baseline}{{10}{16}{Optimisation du seuil $\gamma $ pour le modèle à partir des sentiments moyens des mots\relax }{figure.caption.13}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Prédire le sentiment d'un tweet à partir des \emph  {word-embeddings}}{16}{subsection.3.1}\protected@file@percent }
\newlabel{pruxe9dire-le-sentiment-dun-tweet-uxe0-partir-des-word-embeddings}{{3.1}{16}{\texorpdfstring {Prédire le sentiment d'un tweet à partir des \emph {word-embeddings}}{Prédire le sentiment d'un tweet à partir des word-embeddings}}{subsection.3.1}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.1.1}Prédiction à partir du sentiment moyen des mots}{16}{subsubsection.3.1.1}\protected@file@percent }
\newlabel{sec:sentiments}{{3.1.1}{16}{Prédiction à partir du sentiment moyen des mots}{subsubsection.3.1.1}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.1.2}Prédiction à partir des \emph  {word-embeddings}}{17}{subsubsection.3.1.2}\protected@file@percent }
\newlabel{sec:wordembeddings}{{3.1.2}{17}{\texorpdfstring {Prédiction à partir des \emph {word-embeddings}}{Prédiction à partir des word-embeddings}}{subsubsection.3.1.2}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.1.3}Les limites des modèles utilisés}{18}{subsubsection.3.1.3}\protected@file@percent }
\newlabel{les-limites-des-moduxe8les-utilisuxe9s}{{3.1.3}{18}{Les limites des modèles utilisés}{subsubsection.3.1.3}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.1.4}Les mots inconnus}{18}{subsubsection.3.1.4}\protected@file@percent }
\newlabel{les-mots-inconnus}{{3.1.4}{18}{Les mots inconnus}{subsubsection.3.1.4}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.1.5}Le processus d'annotation utilisé par la SNCF}{18}{subsubsection.3.1.5}\protected@file@percent }
\newlabel{le-processus-dannotation-utilisuxe9-par-la-sncf}{{3.1.5}{18}{Le processus d'annotation utilisé par la SNCF}{subsubsection.3.1.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces Part des mots inconnus dans les tweets\relax }}{19}{figure.caption.14}\protected@file@percent }
\newlabel{fig:mots_inconnus}{{11}{19}{Part des mots inconnus dans les tweets\relax }{figure.caption.14}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.1.6}Le domain-shift}{19}{subsubsection.3.1.6}\protected@file@percent }
\newlabel{le-domain-shift}{{3.1.6}{19}{Le domain-shift}{subsubsection.3.1.6}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Sentiments des tweets et enquête de conjoncture auprès des ménages {[}Alain{]}}{20}{subsection.3.2}\protected@file@percent }
\newlabel{sentiments-des-tweets-et-enquuxeate-de-conjoncture-aupruxe8s-des-muxe9nages-alain}{{3.2}{20}{Sentiments des tweets et enquête de conjoncture auprès des ménages {[}Alain{]}}{subsection.3.2}{}}
\newlabel{conclusion-suxfbrement-kim}{{3.2}{20}{Conclusion {[}sûrement Kim{]}}{section*.15}{}}
\@writefile{toc}{\contentsline {section}{Conclusion {[}sûrement Kim{]}}{20}{section*.15}\protected@file@percent }
\citation{Schakel}
\citation{Mikolov}
\citation{Mikolov}
\citation{Levy}
\@writefile{toc}{\contentsline {section}{\numberline {A}Comment évaluer le modèle ?}{21}{appendix.A}\protected@file@percent }
\newlabel{annexe:commentEvaluer}{{A}{21}{Comment évaluer le modèle ?}{appendix.A}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.1}Distance entre deux mots}{21}{subsection.A.1}\protected@file@percent }
\newlabel{distance-entre-deux-mots}{{A.1}{21}{Distance entre deux mots}{subsection.A.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.2}Analyse en Composantes Principales}{21}{subsection.A.2}\protected@file@percent }
\newlabel{analyse-en-composantes-principales}{{A.2}{21}{Analyse en Composantes Principales}{subsection.A.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.3}Algorithme \emph  {t-distributed Stochastic Neighbor Embedding}}{23}{subsection.A.3}\protected@file@percent }
\newlabel{algorithme-t-distributed-stochastic-neighbor-embedding}{{A.3}{23}{\texorpdfstring {Algorithme \emph {t-distributed Stochastic Neighbor Embedding}}{Algorithme t-distributed Stochastic Neighbor Embedding}}{subsection.A.3}{}}
\citation{Rubenstein}
\citation{Boumedyen}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {A.3.1}Jugement humain}{24}{subsubsection.A.3.1}\protected@file@percent }
\newlabel{sec:jugementHumain}{{A.3.1}{24}{Jugement humain}{subsubsection.A.3.1}{}}
\citation{*}
\bibcite{Bengio}{{1}{2003}{{Bengio \emph  {et al} }}{{}}}
\bibcite{Boumedyen}{{2}{2017}{{Boumedyen Billami \& Gala }}{{}}}
\bibcite{Candela}{{3}{2009}{{Candela et al. }}{{}}}
\bibcite{Hutter}{{4}{2014}{{Hutter, Hoos \& Leyton-Brown }}{{}}}
\bibcite{Jurafsky}{{5}{2019}{{Jurafsky \& Martin }}{{}}}
\bibcite{Levy}{{6}{2015}{{Levy \& Golberg }}{{}}}
\bibcite{Levy2}{{7}{2014}{{Levy \& Golberg }}{{}}}
\bibcite{Mikolov}{{8}{2013a}{{Mikolov \emph  {et al} }}{{}}}
\bibcite{MikolovNS}{{9}{2013b}{{Mikolov \emph  {et al} }}{{}}}
\bibcite{Pennington}{{10}{2014}{{Pennington, Socher \& Manning }}{{}}}
\bibcite{Rehurek}{{11}{2010}{{{\v R}eh{\r u}{\v r}ek \& Sojka }}{{}}}
\bibcite{Rubenstein}{{12}{1965}{{Rubenstein \& Goodenough }}{{}}}
\bibcite{Schakel}{{13}{2015}{{Schakel \& Wilson }}{{}}}
\@writefile{lot}{\contentsline {table}{\numberline {4}{\ignorespaces Base de données de jugement humain\relax }}{25}{table.caption.16}\protected@file@percent }
\newlabel{table:human_judgement}{{4}{25}{Base de données de jugement humain\relax }{table.caption.16}{}}
